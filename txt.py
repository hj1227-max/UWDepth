# def modify_file_content(filename):
#     with open(filename, 'r', encoding='utf-8') as file:
#         lines = file.readlines()
#
#     modified_lines = []
#     for line in lines:
#         parts = line.strip().split()
#         if len(parts) >= 2:
#             # å¤„ç†è·¯å¾„éƒ¨åˆ†ï¼Œå»æ‰é‡å¤çš„flatiron
#             path_parts = parts[0].split('/')
#             if len(path_parts) == 3 and path_parts[1] == path_parts[2]:
#                 new_path = '/'.join(path_parts[:2])
#                 # é‡æ–°ç»„åˆè¡Œå†…å®¹
#                 new_line = new_path + ' ' + ' '.join(parts[1:])
#                 modified_lines.append(new_line)
#             else:
#                 modified_lines.append(line.strip())
#         else:
#             modified_lines.append(line.strip())
#
#     # å†™å›æ–‡ä»¶
#     with open(filename, 'w', encoding='utf-8') as file:
#         for line in modified_lines:
#             file.write(line + '\n')
#
#
# # ä½¿ç”¨ç¤ºä¾‹
# modify_file_content("/mnt/data_sdd/hj/WaterMono-main/splits/OUC/train_files.txt")

'''
import os
from glob import glob

import os
from glob import glob


def main():
    base_dir = "/mnt/data_sdd/hj/datasets/water/"
    categories = ['canyons', 'red_sea']

    # æ”¯æŒçš„å›¾ç‰‡æ‰©å±•å
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']

    test_lines = []
    val_lines = []
    train_lines = []

    for category in categories:
        # è·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆåªåŒ…å«ç›®å½•ï¼‰
        sub_dirs = [d for d in glob(os.path.join(base_dir, category, '*')) if os.path.isdir(d)]

        print(f"åœ¨ {category} ä¸­æ‰¾åˆ° {len(sub_dirs)} ä¸ªå­æ–‡ä»¶å¤¹")

        for sub_dir in sub_dirs:
            img_dir = os.path.join(sub_dir, 'imgs')
            if not os.path.exists(img_dir):
                print(f"è­¦å‘Š: {img_dir} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶å¹¶æŒ‰åç§°æ’åº
            all_files = os.listdir(img_dir)
            # è¿‡æ»¤å‡ºå›¾ç‰‡æ–‡ä»¶
            img_files = [f for f in all_files if os.path.splitext(f)[1].lower() in image_extensions]

            if not img_files:
                print(f"è­¦å‘Š: {img_dir} ä¸­æ²¡æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œè·³è¿‡")
                continue

            img_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
            total_images = len(img_files)

            # æå–ç›¸å¯¹è·¯å¾„å‰ç¼€
            rel_path = f"{category}/{os.path.basename(sub_dir)}"

            print(f"å¤„ç† {rel_path}: æ‰¾åˆ° {total_images} å¼ å›¾ç‰‡")

            # å¤„ç†å‰300å¼  -> test
            for img in img_files[:300]:
                img_name = os.path.splitext(img)[0]  # ç§»é™¤æ‰©å±•å
                test_lines.append(f"{rel_path} {img_name}")

            # å¤„ç†301-350å¼  -> val
            if total_images > 300:
                for img in img_files[300:350]:
                    img_name = os.path.splitext(img)[0]
                    val_lines.append(f"{rel_path} {img_name}")

            # å¤„ç†å‰©ä½™å¼  -> train
            if total_images > 350:
                for img in img_files[350:]:
                    img_name = os.path.splitext(img)[0]
                    train_lines.append(f"{rel_path} {img_name}")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = "/mnt/data_sdd/hj/WaterMono-main/splits/OUC"
    os.makedirs(output_dir, exist_ok=True)

    # å†™å…¥ç»“æœæ–‡ä»¶
    with open(os.path.join(output_dir, "test_files.txt"), 'w') as f:
        f.write('\n'.join(test_lines))

    with open(os.path.join(output_dir, "val_files.txt"), 'w') as f:
        f.write('\n'.join(val_lines))

    with open(os.path.join(output_dir, "train_files.txt"), 'w') as f:
        f.write('\n'.join(train_lines))

    print("\næ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
    print(f"æµ‹è¯•é›†: {len(test_lines)} æ¡è®°å½•")
    print(f"éªŒè¯é›†: {len(val_lines)} æ¡è®°å½•")
    print(f"è®­ç»ƒé›†: {len(train_lines)} æ¡è®°å½•")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
'''
'''
import os


def extract_every_nth_line(input_file, output_file, n=6, start_line=1):
    """
    ä»TXTæ–‡ä»¶ä¸­æå–æ¯nè¡Œçš„ç¬¬start_lineè¡Œ
    """
    try:
        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = [line.rstrip('\n\r') for line in f]

        # æå–å¯¹åº”çš„è¡Œ
        extracted_lines = []
        current_index = start_line - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•

        while current_index < len(lines):
            extracted_lines.append(lines[current_index])
            current_index += n

        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f_out:
            f_out.write('\n'.join(extracted_lines))

        print(f"å®Œæˆ! ä» {input_file} æå–äº† {len(extracted_lines)} è¡Œåˆ° {output_file}")
        return True

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False


# ç›´æ¥ä½¿ç”¨
if __name__ == "__main__":
    input_file = "/mnt/data_sdd/hj/WaterMono-main/splits/OUC/test_files.txt"  # æ›¿æ¢ä¸ºä½ çš„è¾“å…¥æ–‡ä»¶è·¯å¾„
    output_file = "/mnt/data_sdd/hj/WaterMono-main/splits/OUC/output_combined.txt"  # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    n = 6  # é—´éš”è¡Œæ•°
    start_line = 1  # æ¯ç»„ä¸­çš„ç¬¬å‡ è¡Œ

    extract_every_nth_line(input_file, output_file, n, start_line)
'''


'''
#numpy==2.0.2,tensorFlow==2.20.0
import os
import io
import matplotlib.pyplot as plt
from PIL import Image
from tensorboard.backend.event_processing import event_accumulator

#====================#
# 1. è®¾ç½®äº‹ä»¶æ–‡ä»¶è·¯å¾„
#====================#
event_path = "/mnt/data_sdd/hj/WaterMono-main/tmp/mygai/train/events.out.tfevents.1760010962.vip-Precision-7920-Tower"
if not os.path.exists(event_path):
    raise FileNotFoundError(f"æœªæ‰¾åˆ°äº‹ä»¶æ–‡ä»¶ï¼š{event_path}")

#====================#
# 2. åŠ è½½äº‹ä»¶æ–‡ä»¶
#====================#
ea = event_accumulator.EventAccumulator(event_path, size_guidance={
    event_accumulator.SCALARS: 0,
    event_accumulator.IMAGES: 0,
    event_accumulator.HISTOGRAMS: 0,
})
ea.Reload()

#====================#
# 3. æ‰“å°å¯ç”¨æ ‡ç­¾
#====================#
print("\n==================== å¯ç”¨æ•°æ®æ ‡ç­¾ ====================")
print("æ ‡é‡ (scalars):", ea.Tags().get('scalars', []))
print("å›¾åƒ (images):", ea.Tags().get('images', []))
print("ç›´æ–¹å›¾ (histograms):", ea.Tags().get('histograms', []))
print("======================================================\n")

#====================#
# 4. ç»˜åˆ¶æŸå¤±æ›²çº¿
#====================#
if 'train/loss' in ea.Tags().get('scalars', []):
    scalars = ea.Scalars('train/loss')
    steps = [s.step for s in scalars]
    values = [s.value for s in scalars]

    plt.figure(figsize=(8,5))
    plt.plot(steps, values, label='train/loss', color='blue')
    plt.xlabel('Step')
    plt.ylabel('Loss')
    plt.title('Training Loss Curve')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("train_loss_curve.png", dpi=300)
    plt.close()
    print("âœ… å·²ä¿å­˜æŸå¤±æ›²çº¿ï¼štrain_loss_curve.png")
else:
    print("âš ï¸ æœªæ‰¾åˆ° 'train/loss' æ ‡é‡æ ‡ç­¾ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ‰“å°çš„æ ‡ç­¾åç§°å¹¶æ›¿æ¢ã€‚")

#====================#
# 5. ä¿å­˜äº‹ä»¶æ–‡ä»¶ä¸­çš„å›¾åƒ
#====================#
save_dir = "/mnt/data_sdd/hj/WaterMono-main/tmp/mygai/train/event_images/"
os.makedirs(save_dir, exist_ok=True)

image_tags = ea.Tags().get('images', [])
if image_tags:
    print(f"\näº‹ä»¶æ–‡ä»¶ä¸­åŒ…å« {len(image_tags)} ä¸ªå›¾åƒæ ‡ç­¾ï¼š{image_tags}")

    for tag in image_tags:
        images = ea.Images(tag)
        print(f"\nğŸ”¹ ä¿å­˜å›¾åƒæ ‡ç­¾: {tag}ï¼ˆå…± {len(images)} å¼ ï¼‰")

        for i, img_event in enumerate(images):
            image_data = img_event.encoded_image_string
            image = Image.open(io.BytesIO(image_data))

            # æ„é€ ä¿å­˜è·¯å¾„
            filename = f"{tag.replace('/', '_')}_step{img_event.step:06d}.png"
            save_path = os.path.join(save_dir, filename)
            image.save(save_path)
        print(f"âœ… {tag}: å·²ä¿å­˜ {len(images)} å¼ å›¾åƒåˆ° {save_dir}")
else:
    print("âš ï¸ æœªåœ¨äº‹ä»¶æ–‡ä»¶ä¸­å‘ç°å›¾åƒæ•°æ®ã€‚")

print("\nâœ… æ‰€æœ‰å›¾åƒå·²ä¿å­˜è‡³ï¼š", os.path.abspath(save_dir))

'''

#æ‰¹é‡å°†tifå›¾è½¬ä¸ºpngå›¾
import os
import numpy as np
from PIL import Image

# ============ å‚æ•°è®¾ç½® ============
input_folder = "/mnt/data_sdd/hj/datasets/water/canyons/tiny_canyon/depth/"   # è¾“å…¥æ–‡ä»¶å¤¹
output_folder = "/mnt/data_sdd/hj/datasets/water/canyons/tiny_canyon/depth1/"  # è¾“å‡ºæ–‡ä»¶å¤¹
os.makedirs(output_folder, exist_ok=True)

# ============ å‡½æ•°å®šä¹‰ ============
def normalize_to_uint8(arr):
    """å°†æµ®ç‚¹æˆ–æ•´å‹å›¾åƒå½’ä¸€åŒ–åˆ° [0,255]"""
    arr = arr.astype(np.float32)
    min_val, max_val = np.min(arr), np.max(arr)
    if max_val - min_val < 1e-8:
        return np.zeros_like(arr, dtype=np.uint8)
    arr = (arr - min_val) / (max_val - min_val)
    arr = (arr * 255).clip(0, 255).astype(np.uint8)
    return arr

def convert_tif_to_png(input_path, output_path):
    """å•å¼  TIF è½¬ PNG"""
    try:
        with Image.open(input_path) as img:
            arr = np.array(img)

            # å¦‚æœæ˜¯æµ®ç‚¹å›¾æˆ–16ä½å›¾ -> å½’ä¸€åŒ–
            if arr.dtype in [np.float32, np.float64, np.uint16, np.int16]:
                arr = normalize_to_uint8(arr)

            # ä¿å­˜ä¸º PNG
            Image.fromarray(arr).save(output_path)
            print(f"âœ… å·²è½¬æ¢: {input_path} â†’ {output_path}")

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {input_path}")
        print(f"   é”™è¯¯ä¿¡æ¯: {e}")

# ============ ä¸»ç¨‹åº ============
for file_name in os.listdir(input_folder):
    if file_name.lower().endswith(('.tif', '.tiff')):
        in_path = os.path.join(input_folder, file_name)
        out_path = os.path.join(output_folder, os.path.splitext(file_name)[0] + '.png')
        convert_tif_to_png(in_path, out_path)

print("ğŸ‰ å…¨éƒ¨è½¬æ¢å®Œæˆï¼")

'''

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

#====================#
# 1. è®¾ç½®è·¯å¾„
#====================#
pred_path = "/mnt/data_sdd/hj/datasets/water/canyons/flatiron/imgs/16233053670626626.jpg"    # é¢„æµ‹æ·±åº¦å›¾è·¯å¾„
gt_path   = "/mnt/data_sdd/hj/datasets/water/canyons/flatiron/imgs/16233053670626626_disp.jpeg"     # çœŸå®æ·±åº¦å›¾è·¯å¾„
save_path = "/mnt/data_sdd/hj/datasets/water/canyons/flatiron/rmse_map.png"       # ä¿å­˜è¯¯å·®å›¾è·¯å¾„

#====================#
# 2. è¯»å–å›¾åƒ
#====================#
pred = cv2.imread(pred_path, cv2.IMREAD_UNCHANGED)
gt = cv2.imread(gt_path, cv2.IMREAD_UNCHANGED)

if pred is None or gt is None:
    raise FileNotFoundError("âŒ å›¾åƒè·¯å¾„é”™è¯¯ï¼Œè¯·æ£€æŸ¥ pred_path å’Œ gt_path")

#====================#
# 3. è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆè‹¥ä¸ºä¸‰é€šé“ï¼‰
#====================#
if len(pred.shape) == 3:
    pred = cv2.cvtColor(pred, cv2.COLOR_BGR2GRAY)
if len(gt.shape) == 3:
    gt = cv2.cvtColor(gt, cv2.COLOR_BGR2GRAY)

#====================#
# 4. å°ºå¯¸å¯¹é½
#====================#
if pred.shape != gt.shape:
    gt = cv2.resize(gt, (pred.shape[1], pred.shape[0]), interpolation=cv2.INTER_LINEAR)

#====================#
# 5. è½¬ float32 å¹¶å½’ä¸€åŒ–åˆ° [0,1]
#====================#
pred = pred.astype(np.float32)
gt = gt.astype(np.float32)
pred /= (pred.max() + 1e-8)
gt /= (gt.max() + 1e-8)

#====================#
# 6. è®¡ç®— RMSE map
#====================#
error_map = (pred - gt) ** 2
rmse_value = np.sqrt(np.mean(error_map))
rmse_map = np.sqrt(error_map)

print(f"âœ… å›¾åƒ RMSE: {rmse_value:.6f}")

#====================#
# 7. å¯è§†åŒ–å¹¶ä¿å­˜
#====================#
plt.figure(figsize=(6,5))
plt.imshow(rmse_map, cmap='inferno')
plt.colorbar(label='RMSE per pixel')
plt.title(f"RMSE Map (RMSE={rmse_value:.4f})")
plt.axis('off')

plt.tight_layout()
plt.savefig(save_path, dpi=300, bbox_inches='tight')
plt.close()
print(f"ğŸ’¾ å·²ä¿å­˜è¯¯å·®å›¾åˆ°: {os.path.abspath(save_path)}")
'''






